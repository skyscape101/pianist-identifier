{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47dc4a57-cc01-45fa-aee5-e551a26126c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the CSV file\n",
    "metadata = pd.read_csv('ATEPP-metadata-1.1.csv')\n",
    "\n",
    "# Filter data for compositions by Ludwig van Beethoven\n",
    "beethoven_data = metadata[metadata['composer'] == 'Ludwig van Beethoven']\n",
    "\n",
    "# Filter out necessary columns\n",
    "filtered_metadata = beethoven_data[['artist', 'midi_path']]\n",
    "\n",
    "# Get artist counts\n",
    "artist_counts = filtered_metadata['artist'].value_counts()\n",
    "\n",
    "# Identify the top 5 artists with the most records\n",
    "top_artists = artist_counts.head(5).index\n",
    "\n",
    "# Randomly select 300 records for each of the top artists\n",
    "selected_data = filtered_metadata[filtered_metadata['artist'].isin(top_artists)]\n",
    "sampled_data = selected_data.groupby('artist').apply(lambda x: x.sample(n=300, random_state=36)).reset_index(drop=True)\n",
    "\n",
    "# Encode the 'artist' column\n",
    "le = LabelEncoder()\n",
    "sampled_data['artist_encoded'] = le.fit_transform(sampled_data['artist'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(sampled_data, test_size=0.2, stratify=sampled_data['artist_encoded'], random_state=42)\n",
    "\n",
    "# Reset the indices\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16ebb8-b4a5-464b-95ef-a99c74154ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "\n",
    "def process_midi_files_to_piano_rolls(midi_paths, fs=100, max_len=10000, pitch_range=(20, 100)):\n",
    "    \"\"\"\n",
    "    Convert a list of MIDI files to padded piano roll representations with the same shape.\n",
    "    \n",
    "    Args:\n",
    "        midi_paths (list): List of paths to MIDI files.\n",
    "        fs (int): Sampling frequency for the piano roll.\n",
    "        max_len (int, optional): The maximum length to pad or truncate sequences to. \n",
    "                                 If not provided, it uses the length of the longest sequence.\n",
    "        pitch_range (tuple, optional): Tuple representing the range of pitches to retain. Defaults to (20, 100).\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Array of padded piano roll representations with the same shape.\n",
    "    \"\"\"\n",
    "    \n",
    "    def midi_to_piano_roll(midi_path):\n",
    "        try:\n",
    "            midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
    "            piano_roll = midi_data.get_piano_roll(fs=fs)\n",
    "            \n",
    "            # Cut to the specified pitch range and transpose to have time on the x-axis\n",
    "            return piano_roll[pitch_range[0]:pitch_range[1]].T\n",
    "        except Exception as e:\n",
    "            print(f\"Error encountered while parsing file: {midi_path}, Error: {e}\")\n",
    "            return None\n",
    "        \n",
    "    padded_sequences = []\n",
    "    for path in tqdm(midi_paths, desc=\"Processing MIDI files\"):\n",
    "        piano_roll = midi_to_piano_roll(path)\n",
    "        if piano_roll is not None:\n",
    "            if len(piano_roll) < max_len:\n",
    "                num_padding = max_len - len(piano_roll)\n",
    "                padded_seq = np.pad(piano_roll, ((0, num_padding), (0, 0)), 'constant')\n",
    "            else:\n",
    "                padded_seq = piano_roll[:max_len]\n",
    "            padded_sequences.append(padded_seq)\n",
    "    \n",
    "    return np.array(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e2d687-a40b-4e68-ac67-3c5620eb4004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_midi_paths = train_df['midi_path'].tolist()\n",
    "test_midi_paths = test_df['midi_path'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff89526-3d6d-4074-b2cb-848ce794c13b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_padded_piano_rolls = process_midi_files_to_piano_rolls(train_midi_paths)\n",
    "test_padded_piano_rolls = process_midi_files_to_piano_rolls(test_midi_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66125567-64fd-4865-b435-941b24591eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the arrays\n",
    "np.save('X_train_padded2.npy', train_padded_piano_rolls)\n",
    "np.save('X_test_padded2.npy', test_padded_piano_rolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c1b2e-8784-46dd-8563-03c08b58d00a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mido\n",
    "from mido import MidiFile\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def extract_features_from_midi(midi_file_path):\n",
    "    # Load the MIDI file\n",
    "    mid = MidiFile(midi_file_path)\n",
    "\n",
    "    # Initialize lists to store IOIs, OTDs, and DLs\n",
    "    iois = []\n",
    "    ot_ds = []\n",
    "    dl_s = []\n",
    "    pedal_presses = []\n",
    "    pedal_durations = []\n",
    "\n",
    "    # Variables for polyphony and articulation\n",
    "    notes_on = 0\n",
    "    max_polyphony = 0\n",
    "    legato_count = 0\n",
    "    staccato_count = 0\n",
    "\n",
    "    # Iterate through MIDI tracks and messages\n",
    "    for track in mid.tracks:\n",
    "        prev_time = 0\n",
    "        prev_note_off_time = 0\n",
    "        pedal_down_time = None\n",
    "        for msg in track:\n",
    "            # Calculate absolute time of the message\n",
    "            absolute_time = prev_time + msg.time\n",
    "            if msg.type == 'note_on' and msg.velocity > 0:\n",
    "                notes_on += 1\n",
    "                max_polyphony = max(max_polyphony, notes_on)\n",
    "\n",
    "                # Calculate IOI (Inter-Onset Interval)\n",
    "                ioi = absolute_time - prev_note_off_time\n",
    "                iois.append(ioi)\n",
    "\n",
    "                # Store the dynamic level (velocity)\n",
    "                dl_s.append(msg.velocity)\n",
    "\n",
    "                prev_time = absolute_time\n",
    "\n",
    "            elif msg.type == 'note_off' or (msg.type == 'note_on' and msg.velocity == 0):\n",
    "                notes_on -= 1\n",
    "\n",
    "                # Calculate OTD (Off-Time Duration)\n",
    "                otd = absolute_time - prev_time\n",
    "                ot_ds.append(otd)\n",
    "\n",
    "                # Determine if the note is legato or staccato\n",
    "                if otd >= ioi:\n",
    "                    legato_count += 1\n",
    "                else:\n",
    "                    staccato_count += 1\n",
    "\n",
    "                prev_note_off_time = absolute_time\n",
    "\n",
    "            # Pedal usage\n",
    "            if msg.type == 'control_change' and msg.control == 64:\n",
    "                if msg.value > 0:  # Pedal pressed\n",
    "                    pedal_presses.append(absolute_time)\n",
    "                    pedal_down_time = absolute_time\n",
    "                else:  # Pedal released\n",
    "                    if pedal_down_time:\n",
    "                        pedal_duration = absolute_time - pedal_down_time\n",
    "                        pedal_durations.append(pedal_duration)\n",
    "                        pedal_down_time = None\n",
    "\n",
    "    # Calculate the standard deviations for IOI, OTD, and DL\n",
    "    std_ioi = np.std(iois) if iois else 0\n",
    "    std_otd = np.std(ot_ds) if ot_ds else 0\n",
    "    std_dl = np.std(dl_s) if dl_s else 0\n",
    "\n",
    "    # Calculate pedal usage metrics\n",
    "    avg_pedal_duration = np.mean(pedal_durations) if pedal_durations else 0\n",
    "    pedal_frequency = len(pedal_presses) / (mid.length if mid.length > 0 else 1)\n",
    "\n",
    "    # Calculate legato to staccato ratio\n",
    "    legato_staccato_ratio = legato_count / staccato_count if staccato_count > 0 else legato_count\n",
    "\n",
    "    return np.array([std_ioi, std_otd, std_dl, max_polyphony, avg_pedal_duration, pedal_frequency, legato_staccato_ratio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6480f-4c00-4963-9b0b-6eb27be85b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = [extract_features_from_midi(path) for path in tqdm(train_midi_paths, desc=\"Extracting Features\")]\n",
    "test_features = [extract_features_from_midi(path) for path in tqdm(test_midi_paths, desc=\"Extracting Features\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee98bd61-dedf-4f31-83b1-6d2b55ecdd27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the arrays\n",
    "np.save('X_train_features4.npy', train_features)\n",
    "np.save('X_test_features4.npy', test_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
